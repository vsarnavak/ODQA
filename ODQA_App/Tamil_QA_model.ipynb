{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR_bd6b70h76",
        "outputId": "ee954cb7-dde6-41e8-ac72-2b2618b819a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Collecting indicnlp\n",
            "  Downloading indicnlp-0.0.1-py3-none-any.whl.metadata (516 bytes)\n",
            "Downloading indicnlp-0.0.1-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: indicnlp\n",
            "Successfully installed indicnlp-0.0.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n",
            "Downloading sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.2/255.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.0.1-py3-none-any.whl (471 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, dill, multiprocess, sentence-transformers, datasets\n",
            "Successfully installed datasets-3.0.1 dill-0.3.8 multiprocess-0.70.16 sentence-transformers-3.2.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "!pip install nltk\n",
        "!pip install beautifulsoup4 requests\n",
        "!pip install indicnlp\n",
        "!pip install transformers torch sentence-transformers datasets\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install beautifulsoup4 requests\n",
        "!pip install indicnlp\n",
        "!pip install transformers torch sentence-transformers datasets\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "!pip install indic-nlp-library\n",
        "from indicnlp import common\n",
        "\n",
        "# Set the path to the Indic NLP Resources directory\n",
        "INDIC_NLP_RESOURCES = \"/path_to_resources\"\n",
        "\n",
        "common.set_resources_path(INDIC_NLP_RESOURCES)\n",
        "\n",
        "\n",
        "import indicnlp\n",
        "from indicnlp.tokenize import indic_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZyIgDed0m0f",
        "outputId": "c21b1591-2084-4c64-b540-312e1063ec3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: indicnlp in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.4.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting indic-nlp-library\n",
            "  Downloading indic_nlp_library-0.92-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting sphinx-argparse (from indic-nlp-library)\n",
            "  Downloading sphinx_argparse-0.5.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting sphinx-rtd-theme (from indic-nlp-library)\n",
            "  Downloading sphinx_rtd_theme-3.0.1-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting morfessor (from indic-nlp-library)\n",
            "  Downloading Morfessor-2.0.6-py3-none-any.whl.metadata (628 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from indic-nlp-library) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->indic-nlp-library) (2024.2)\n",
            "Collecting sphinx>=5.1.0 (from sphinx-argparse->indic-nlp-library)\n",
            "  Downloading sphinx-8.1.3-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting docutils>=0.19 (from sphinx-argparse->indic-nlp-library)\n",
            "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->indic-nlp-library)\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->indic-nlp-library) (1.16.0)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.9 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.1.4)\n",
            "Requirement already satisfied: Pygments>=2.17 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.18.0)\n",
            "Requirement already satisfied: snowballstemmer>=2.2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.0)\n",
            "Requirement already satisfied: babel>=2.13 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.16.0)\n",
            "Requirement already satisfied: alabaster>=0.7.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (0.7.16)\n",
            "Requirement already satisfied: imagesize>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.30.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.32.3)\n",
            "Requirement already satisfied: packaging>=23.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (24.1)\n",
            "Requirement already satisfied: tomli>=2 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.30.0->sphinx>=5.1.0->sphinx-argparse->indic-nlp-library) (2024.8.30)\n",
            "Downloading indic_nlp_library-0.92-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Morfessor-2.0.6-py3-none-any.whl (35 kB)\n",
            "Downloading sphinx_argparse-0.5.2-py3-none-any.whl (12 kB)\n",
            "Downloading sphinx_rtd_theme-3.0.1-py2.py3-none-any.whl (7.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinx-8.1.3-py3-none-any.whl (3.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: morfessor, docutils, sphinx, sphinxcontrib-jquery, sphinx-argparse, sphinx-rtd-theme, indic-nlp-library\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.18.1\n",
            "    Uninstalling docutils-0.18.1:\n",
            "      Successfully uninstalled docutils-0.18.1\n",
            "  Attempting uninstall: sphinx\n",
            "    Found existing installation: Sphinx 5.0.2\n",
            "    Uninstalling Sphinx-5.0.2:\n",
            "      Successfully uninstalled Sphinx-5.0.2\n",
            "Successfully installed docutils-0.21.2 indic-nlp-library-0.92 morfessor-2.0.6 sphinx-8.1.3 sphinx-argparse-0.5.2 sphinx-rtd-theme-3.0.1 sphinxcontrib-jquery-4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "from indicnlp.tokenize import indic_tokenize\n",
        "from indicnlp.normalize.indic_normalize import IndicNormalizerFactory\n",
        "\n",
        "# List of common Tamil stop words\n",
        "tamil_stop_words = [\n",
        "    \"மற்றும்\", \"இது\", \"அது\", \"இவை\", \"அவை\", \"என்று\", \"ஒரு\", \"இல்லை\",\n",
        "    \"உள்ள\", \"என்ற\", \"என்ன\", \"இருந்து\", \"யார்\", \"எப்போது\", \"எங்கே\",\n",
        "    \"ஏன்\", \"எது\", \"எப்படி\", \"எத்தனை\", \"கொண்டு\", \"போல\", \"என\"\n",
        "]\n",
        "\n",
        "# Function to remove suffixes\n",
        "def remove_suffixes(word):\n",
        "    suffixes = [\"ன்\", \"ம்\", \"கள்\", \"து\", \"ல்\", \"டன்\", \"னின்\", \"அ\", \"ஆ\", \"உம்\", \"இன்\", \"கின்\", \"அவ்\"]\n",
        "    for suffix in suffixes:\n",
        "        if word.endswith(suffix):\n",
        "            return word\n",
        "    return word\n",
        "\n",
        "# Function to fix endings after suffix removal\n",
        "def fix_endings(word):\n",
        "    if word.endswith(\"ட்டின்\"):\n",
        "        word = word.replace('ட்டின்', \"டு\")\n",
        "    elif word.endswith(\"வின்\"):\n",
        "        word = word.replace(\"வின்\", \"\")\n",
        "    elif word.endswith(\"ங்கள்\"):\n",
        "        word = word[:-1] + \"ம்\"\n",
        "    elif word.endswith(\"ற்\"):\n",
        "        word = word[:-1] + \"ற\"\n",
        "    elif word.endswith(\"வ்\"):\n",
        "        word = word[:-1] + \"வ\"\n",
        "    return word\n",
        "\n",
        "# Complete Tamil stemmer function\n",
        "def tamil_stemmer(word):\n",
        "    word = remove_suffixes(word)\n",
        "    word = fix_endings(word)\n",
        "    return word\n",
        "\n",
        "# Function to process tokens with stemming\n",
        "def process_tokens(words_list):\n",
        "    tamil_regex = r'[^\\u0B80-\\u0BFF ]+'  # Tamil Unicode range\n",
        "    filtered_words = []\n",
        "    for word in words_list:\n",
        "        cleaned_word = re.sub(tamil_regex, '', word).strip()\n",
        "        stemmed_word = tamil_stemmer(cleaned_word)\n",
        "        if stemmed_word and stemmed_word not in tamil_stop_words:\n",
        "            filtered_words.append(stemmed_word)\n",
        "    return filtered_words\n",
        "\n",
        "# Tokenize and stem the question\n",
        "def tokenize_question(question):\n",
        "    factory = IndicNormalizerFactory()\n",
        "    normalizer = factory.get_normalizer(\"ta\")\n",
        "    normalized_text = normalizer.normalize(question)\n",
        "    tokens = list(indic_tokenize.trivial_tokenize(normalized_text, \"ta\"))\n",
        "    tokens = [i for i in tokens if i not in tamil_stop_words]\n",
        "    print(tokens)\n",
        "    processed_tokens_list = process_tokens(tokens)\n",
        "    print(processed_tokens_list)\n",
        "    return processed_tokens_list\n",
        "\n",
        "# Wikipedia search function\n",
        "def wikipedia_search(query, language='ta'):\n",
        "    url = f\"https://{language}.wikipedia.org/w/api.php\"\n",
        "    params = {\n",
        "        'action': 'query',\n",
        "        'list': 'search',\n",
        "        'srsearch': query,\n",
        "        'format': 'json',\n",
        "        'utf8': 1,\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    search_results = response.json()\n",
        "\n",
        "    return search_results['query']['search'] if 'query' in search_results else []\n",
        "\n",
        "# Wikipedia article content extraction function\n",
        "def get_wikipedia_article(title, language='ta'):\n",
        "    url = f\"https://{language}.wikipedia.org/w/api.php\"\n",
        "    params = {\n",
        "        'action': 'query',\n",
        "        'prop': 'extracts',\n",
        "        'exintro': True,\n",
        "        'explaintext': True,\n",
        "        'titles': title,\n",
        "        'format': 'json',\n",
        "        'utf8': 1,\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    pages = response.json()['query']['pages']\n",
        "\n",
        "    for page_id, page in pages.items():\n",
        "        if 'extract' in page:\n",
        "            return page['extract']\n",
        "    return \"\"\n",
        "\n",
        "# Function to answer the question \"endraal enna\" type questions\n",
        "def qa(question, language='ta'):\n",
        "    # Check if the question contains the phrase \"என்றால் என்ன\"\n",
        "    match = re.search(r'(.+?)என்றால்\\s*என்ன', question)\n",
        "    if match:\n",
        "        word_to_define = match.group(1).strip()\n",
        "        print(f\"Searching for: {word_to_define}\")\n",
        "\n",
        "        # Perform Wikipedia search for the extracted word\n",
        "        search_results = wikipedia_search(word_to_define, language)\n",
        "\n",
        "        combined_content = \"\"\n",
        "        for result in search_results:\n",
        "            title = result['title']\n",
        "            content = get_wikipedia_article(title, language)\n",
        "            combined_content += content + \"\\n\"\n",
        "\n",
        "        # Return the extracted content\n",
        "        if combined_content:\n",
        "            return combined_content\n",
        "        else:\n",
        "            return \"Sorry, no relevant information was found.\"\n",
        "    else:\n",
        "        return \"This question doesn't match the 'endraal enna' pattern.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "-sEoAAMk02TD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "OERlmN8p2coZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Unzip the file to a specified directory\n",
        "shutil.unpack_archive('trained_model.zip', './trained_model')"
      ],
      "metadata": {
        "id": "OrVOWxTx2iRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip trained_model.zip -d ./trained_model\n"
      ],
      "metadata": {
        "id": "kqjZkzR4Rx6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49aa5895-f96d-4b07-f864-e9e1ff0c257e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  trained_model.zip\n",
            "replace ./trained_model/vocab.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForQuestionAnswering, BertTokenizer\n",
        "\n",
        "# Load the model and tokenizer from the unzipped directory\n",
        "model = BertForQuestionAnswering.from_pretrained('./trained_model')\n",
        "tokenizer = BertTokenizer.from_pretrained('./trained_model')\n"
      ],
      "metadata": {
        "id": "4yaZry2Q2ezL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "sample questions:\n",
        "\n",
        "*   \"கம்ப்யூட்டர் என்றால் என்ன?\"\n",
        "*   \"திருக்குறள் என்றால் என்ன?\"\n",
        "*   \"முதலமைச்சர் என்றால் என்ன?\"\n",
        "*   \"ஏவூர்தி என்றால் என்ன?\"\n",
        "*   \"நீராவி என்றால் என்ன?\"\n",
        "*   \"பழங்கள் என்றால் என்ன?\"\n",
        "*   \"விடுதலை தினம் என்றால் என்ன?\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yLqkHTRo7-G1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPGs_NjGQ3Ez",
        "outputId": "4711d52f-79e0-4565-f777-255970852da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "\n",
        "test_question = \"ஏவூர்தி என்றால் என்ன?\"\n",
        "test_context = qa(test_question)\n",
        "print(test_context)\n",
        "inputs = tokenizer(test_question, test_context, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "\n",
        "# Find the most probable start and end of the answer\n",
        "start_index = torch.argmax(start_logits)\n",
        "end_index = torch.argmax(end_logits)\n",
        "\n",
        "# Convert tokens to answer\n",
        "\n",
        "answer_tokens = inputs['input_ids'][0][start_index:end_index + 75]\n",
        "answer = tokenizer.decode(answer_tokens)\n",
        "# print(answer)\n",
        "if answer.startswith(\"<s>\"):\n",
        "    answer = answer[3:]\n",
        "if len(answer)!=0:\n",
        "    print(\"Predicted Answer:\", answer)\n",
        "else:\n",
        "    print(\"Sorry:(... Unable to fetch appropriate results!\")\n",
        "end_time = datetime.datetime.now()\n",
        "print(end_time-start_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6EkHJeC05LF",
        "outputId": "1b434692-87f4-4063-da41-a161acc4b87a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for: ஏவூர்தி\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Be aware, overflowing tokens are not returned for the setting you have chosen, i.e. sequence pairs with the 'longest_first' truncation strategy. So the returned list will always be empty even if some tokens have been removed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ஏவூர்தி (Rocket) என்பது ஏவூர்திப் பொறி மூலம் உந்துவிசையைப் பெறும் ஏவுகணை, விண்கலம், விண்ணூர்தி, வானூர்தி போன்றவற்றைக் குறிக்கப் பயன்படுகிறது.  பயன்பாட்டுக்குத் தேவையான எரிபொருள் மற்றும் ஆக்சிகரணி முழுவதும் ஏவூர்தியிலேயே எடுத்துச் செல்லப்படுகிறது.  இதற்கு வளிமண்டலக் காற்று தேவையில்லை.  ஏவூர்திகள் இயற்பியலின் வினை-எதிர்வினை தத்துவத்தில் இயங்குகின்றன.  எரிதல் மூலம் பெறப்பட்ட வெளியேறிகளை அதிக வேகத்தில் பின்புறத்தில் வெளித் தள்ளுவதன் மூலம், ஏவூர்தி பொறிகள் - ஏவூர்திகளை முன் தள்ளுகின்றன.\n",
            "மற்ற வகை உந்துகைகளுடன் ஒப்பு நோக்குகையில், ஏவூர்திகள் - குறைந்த வேகத்தில் செயல்திறன் அற்றவையாக இருக்கின்றன.  ஏவூர்திகள் குறைந்த எடையும் மிகுந்த திறனும் கொண்டவை.  அவை பெருத்த முடுக்கத்தை அடைவதிலும் மிக உயர்வான திசைவேகங்களை எட்டுவதிலும் மிகுந்த செயல் திறன் கொண்டவையாக இருக்கின்றன.\n",
            "சோடியம் பைகார்பனேட்டு ஏவூர்தியானது (Sodium bicarbonate rocket), 35 மிமீ ஒளிப்படச் சுருள் டப்பாவையும் சோடியம் பைகார்பனேட்டுடன், ஒரு காடியின் வினையிலிருந்து பெறப்படும் கார்பன் டை ஆக்சைடு வாயுவின் அழுத்தத்தையும் பயன்படுத்திச் செய்யப்படும் ஒரு மாதிரி ஏவூர்தியாகும். இவ்வகை ஏவூர்திகள் அறிவியல் வகுப்பறைகளில் இயற்பியல் மற்றும் வேதியியல் கொள்கைகளை விளக்குவதற்கு அடிக்கடி பயன்படுத்தப்படுகின்றன. சில சமயங்களில் இது அல்கா-செல்ட்செர் ஏவூர்தி எனவும் அழைக்கப்படுகிறது.\n",
            "புரோட்டான் (Proton) என்பது ருசியா நாட்டின் ஏவூர்தி ஆகும். இது நான்கு நிலைகளைக் கொண்ட ஒரு நீட்டிக்கப்பட்ட ஏவூர்தி ஆகும். வணிக ரீதியாகவும் மற்றும் ருசிய அரசு விண்வெளி அமைப்பின் ஏவுதலுக்காகவும் இது பயன்படுத்தப்படுகிறது. முதல் புரோட்டான் ஏவூர்தி 1965 ஆம் ஆண்டு ஏவப்பட்டது. மேம்படுத்தப்பட்ட தற்போதைய புரோட்டான் ஏவூர்திகள் இன்று வரை பயன்பாட்டில் இருக்கின்றன. ஏவூர்தி வரலாற்றில் அதிக திறனுடைய அதி உந்துகிகள் (heavy boosters) பயன்படுத்தப்படும் ஏவூர்திகளுள் புரோட்டான் ஏவூர்தியும் ஒன்று. அனைத்து புரோட்டான் ஏவூர்திகளும் ருசியாவின் மாஸ்கோவில் அமைந்துள்ள குருநிசேவ் மாகாண ஆராய்ச்சி மற்றும் உற்பத்தி மையத்தில் ( Khrunichev State Research and Production Space Center) தயாரிக்கப்பட்டு பைக்கனூர் விண்வெளி ஏவுதளம் (Baikonur Cosmodrome) ஏவுதளத்திற்கு கிடைமட்டமாக எடுத்துச் செல்லப்படுகிறது. ஏவுதளத்தின் செலுத்து பீடத்தில் (launch pad ) புரோட்டான் ஏவூர்தி செங்குத்தாக நிலைநிறுத்தப்படுகிறது.\n",
            "எலெக்ட்ரான் ஏவூர்தி (Electron) இரண்டு நிலைகளைக் கொண்டது. இது சிறு செயற்கைக் கோள்களை ஏவும் வண்ணம் வடிவமைக்கப்பட்ட ஏவூர்தி ஆகும். அமெரிக்காவின் ராக்கெட் லேப் எனும் நிறுவனம் வணிக ரீதியில் 150 கி.கி எடையுடைய செயற்கைக் கோள்களை ஏவும் பொருட்டு இவ்வேவூர்தியை உருவாக்கியது. 2016 டிசம்பர் அன்று ஏவூர்தியானது செலுத்தத் தகுதியான நிலையை எட்டிவிட்டதாக அறிவிக்கப்பட்டது.\n",
            "ஏவூர்தியின் வரலாறு (History of rockets) என்பது 13 ஆம் நூற்றாண்டில் சீனாவிலிருந்து தொடங்குகிறது. பின்னர் ஏவூர்தித் தொழினுட்பம் வளர்ச்சியடைந்து, மங்கோலியா, இந்தியா, இங்கிலாந்து, அமெரிக்கா மற்றும் உருசியா ஆகிய இடங்களில் பரவியது. இன்றைய தகவல்தொழில்நுட்ப வளர்ச்சியின் உச்சமாக விளங்கும் செயற்கைகோளை சுமந்து சென்று விண்வெளியில் நிலைநிறுத்துவதில் ஏவூர்திகளின் பங்கு அளப்பரியது. அந்த வகையில் விண்வெளி ஆய்வில் மனித சமுதாயம் புதிய நிலையை அடைய ஏவூர்தி தொழில்நுட்பக் கண்டுபிடிப்புதான் அடிப்படை காரணமாக உள்ளது. ஏவூர்தித் தொழில்நுட்பத்தில் கிட்டத்தட்ட ஆயிரத்து ஐநூறு ஆண்டுகளுக்கும் மேற்பட்ட தொடர்ச்சியான ஆய்வுகளின் முடிவில் கி.பி.1942 (1942 AD) ஆம் ஆண்டு தான் ஏவூர்தி தனது மேம்பட்ட முதல் வடிவத்தை எட்டியது. விண்வெளி பயணம் பற்றிய சிந்தனையும் ஏவூர்தி உருவாக்கம் பற்றிய ஆய்வும் கி.மு நான்காம் நூற்றாண்டிலிருந்தே (400 BC) துவங்கியதாகக் கூறப்படுகிறது.\n",
            "போர்களத்தில் பயன்படும் ஏவூர்தி  என்பதற்கு தமிழில் உந்துகணை என்று வழங்கப்படுகிறது. ஏவூர்தி மற்றும் உந்துகணை ஆகிய சொற்கள் வெவ்வேறு பொருளில் தமிழில் வழங்கப்படுகின்றன.\n",
            "தும்பா நிலநடுக்கோட்டு ஏவூர்தி ஏவுதளம் (Thumba Equatorial Rocket Launching Station) என்பது இந்திய விண்வெளித்தளம் ஆகும்.\n",
            "கடுங்குளிர் ஏவூர்தி இயந்திரம் (Cryogenic rocket engine) என்பது செயற்கைக் கோள்களை விண்ணில் செலுத்தும் ஏவூர்தியில் பயன்படுத்தப்படும் இயந்திரம் ஆகும். அதிக எடையுடைய செயற்கைக் கோள்களையும், செலுத்து வாகனத்தையும் விண்வெளியில் அதிக உயரத்தில் செலுத்த இந்த இயந்திரம் பயன்படுத்தப்படுகிறது. இவ்வியந்திரத்தில் கடுங்குளிரில் உள்ள ஆக்ஸிஜன் மற்றும் ஹைட்ரஜன் வளிமங்கள் எரிபொருளாகப் பயன்படுகின்றன. பல்வேறு வகையான வாயுக் கலவைகள் எரிபொருட்களாகப் பரிசோதிக்கப்பட்டபின் இந்த இரு வாயுக்கள் சிறந்தவை என முடிவெடுக்கப்பட்டது. சாடர்ன் V செலுத்து வாகனம் சந்திரனை அடைந்ததற்கு இந்த இயந்திரமே முக்கியக் காரணமாகும்.\n",
            "விண்ணோடத் திட ஏவூர்தி உந்துகலன்கள் (Space Shuttle Solid Rocket Booster) நாசாவின் விண்ணோடத் திட்டத்தில் முதல் இரண்டு நிமிடங்கள் பயன்படுத்தப்படும் அல்லது எரியும் இரண்டு பெரிய வெண்மையான திட ஏவூர்திகளாகும்.  இரண்டும் மொத்தமாக ஒட்டுமொத்த விண்ணோட புறப்படுதலுக்குத் தேவையான 83% உந்துவிசையைத் தருகின்றன.  ஆரஞ்சு வண்ணம் கொண்ட புறக்கலனுக்கு இருபுறமும் இவை அமைந்திருக்கும்.\n",
            "புவி ஒத்தியங்கும் செயற்கைக்கோள் ஏவூர்தி மார்க் III (The Geosynchronous Satellite Launch Vehicle Mark III) புவி ஒத்தியங்கும் வட்டணையில் \n",
            "ஏவப்படும் செயற்கைக்கோள் ஏவூர்தி ஆகும்.  இசுரோ (ISRO)வினால் வடிவமித்துக் கட்டமைக்கப்பட்ட இது ஒரு முறை மட்டுமே ஏவும் மீளப்பயன்பட இயலாத வகை  ஏவூர்தி ஆகும். 5 ஜூன் 2017 அன்று 17:28 மணியளவில் இந்தியாவின் சத்தீசு தவான் விண்வெளி  மையத்திலிருந்து ஜிசாட்-19 (GSAT-19) செயற்கைக்கோளுடன் விண்ணில் ஏவப்பட்டது.இந்த ஏவூர்தியால் புவி ஒத்தியங்கும் வட்டணைக்குச் செயற்கைக் கோள்களைச் செலுத்த இயலும். மேலும் விண்வெளிக்கு மனிதர்களை அனுப்பவும் இயலும். இந்த  ஏவூர்தியின் மூன்றாவது அடுக்கில் தண்ணியக்கப் பொறி பயன்படுத்தப்படுகிறது. இதனால் அதிக எடையுடைய விண்கலங்களை ஏவ இயலும்.\n",
            "விண்ணூர்தி (Spaceplane) என்பது புவியின் வளிமண்டலத்தில் வானூர்தியாகவும் விண்வெளியில் விண்கலமாகவும் செயல்படும் வாகனமாகும்.  இது வானூர்தி மற்றும் விண்கலம் ஆகியவற்றின் பண்புகளை ஒருங்கே கொண்டுள்ளது, இதனை விண்வெளியில் விண்கலம் போல இருக்கவும் பறக்கவும் கூடிய வானூர்தியெனவும் வானூர்திபோல பறக்கக்கூடிய விண்கலம் எனவும் கூறலாம்.  வழக்கமாக, இவை விண்கலங்களில் இறக்கை பொருத்தப்பட்ட வடிவமைப்பைக் கொண்டிருக்கும், ஏற்றுடல் (Lifting body) வடிவங்களும் வடிவமைக்கப்பட்டு சோதனை செய்யப்பட்டுள்ளன.  விண்வெளியை எட்டுவதற்குத் தேவையான உந்துகை ஏவூர்தி மூலமாகவோ காற்றிழுப்புப் பொறிகள் மூலமாகவோ பெறப்படுகிறது.\n",
            "ஒரு வானூர்தி வெற்றிகரமாக வளிமண்டலத்தில் பறப்பதற்கு, அதன் பறத்தலைக் கட்டுப்படுத்தவும் பறத்தலைத் தொடரவும் இயல வேண்டும்.  ஒரு விண்ணூர்தி, வளிமண்டல நுழைவுக்குப் பிறகு தனது பறத்தலைக் கட்டுப்படுத்தவோ தொடரவோ இயலவில்லையெனில், வளிமண்டலத்தில் பறத்தலுக்கு லாயக்கற்றதாகிவிடும்; அதாவது, வெற்றிகரமான விண்ணூர்தியாக இராது.\n",
            "இதுநாள்வரை ஐந்து விண்ணூர்திகள் மட்டுமே வெற்றிகரமாகப் பறந்துள்ளன, அதாவது விண்வெளியிலிருந்து வெற்றிகரமாக வளிமண்டலத்துக்குள் நுழைந்து, பறந்து பத்திரமாகத் தரையிறங்கியுள்ளன. அவையாவன:\n",
            "\n",
            "எக்சு-15 (X-15)\n",
            "விண்ணோடம் (Space Shuttle)\n",
            "பியூரான் (Buran)\n",
            "ஸ்பேஸ்சிப்வன் (SpaceShipOne)\n",
            "எக்சு-37 (X-37)\n",
            "இவை அனைத்துமே ஏவூர்தி மிதவை வானூர்திகளாகும்.  ஏவூர்திகள் மற்றும் ஏவூர்திகளால் எடுத்துச் செல்லப்பட்ட வானூர்திகள் மட்டுமே இதுவரை வெற்றிகரமாக விண்வெளியை அடைந்துள்ளன.  மேற்கூறப்பட்ட ஐந்தில் இரண்டு ஏவூர்தியுந்திய வானூர்திகளாகும், அதாவது ஆயிரக்கணக்கான அடிகள் உயரம் வரை வளிமண்டலத்தில் பறக்கவியலும் தாய்க்கலத்தால் எடுத்துச் செல்லப்பட்டு விடப்படுகின்றன.  மற்ற மூன்றும் செங்குத்துப் புறப்பாடு மற்றும் கிடைமட்டத் தரையிறக்க வாகனங்களாகும், இவற்றிற்குப் புறப்பாடு மற்றும் விண்வெளியை அடைவதற்கு ஏவூர்தி தேவைப்படும்; வளிமண்டல நுழைவு, இறக்கம் மற்றும் தரையிறக்கத்துக்கு வளிமண்டல ஏற்றம் தேவைப்படும்.\n",
            "\n",
            "Predicted Answer: [CLS] ஏவூர்தி என்றால் என்ன? [SEP] ஏவூர்தி ( Rocket ) என்பது ஏவூர்திப் பொறி மூலம் உந்துவிசையைப் பெறும் ஏவுகணை, விண்கலம், விண்ணூர்தி, வானூர்தி போன்றவற்றைக் குறிக்கப் பயன்படுகிறது. பயன்பாட்டுக்குத் தேவையான எரிபொருள் மற்றும் ஆக்சிகரணி\n",
            "0:00:06.163371\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\""
      ],
      "metadata": {
        "id": "5diTIxxPEnBN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}